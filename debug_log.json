{
  "ts": "2025-12-17T19:28:17.145667",
  "source": "local",
  "repo": "kitamura-tetsuo/auto-coder",
  "job": null,
  "command": "uv run pytest --help",
  "exit_code": 0,
  "raw": null,
  "file": null,
  "stderr": "",
  "stdout": "usage: pytest [options] [file_or_dir] [file_or_dir] [...]\n\npositional arguments:\n  file_or_dir\n\ngeneral:\n  -k EXPRESSION         Only run tests which match the given substring\n                        expression. An expression is a Python evaluable\n                        expression where all names are substring-matched against\n                        test names and their parent classes. Example: -k\n                        'test_method or test_other' matches all test functions\n                        and classes whose name contains 'test_method' or\n                        'test_other', while -k 'not test_method' matches those\n                        that don't contain 'test_method' in their names. -k 'not\n                        test_method and not test_other' will eliminate the\n                        matches. Additionally keywords are matched to classes\n                        and functions containing extra names in their\n                        'extra_keyword_matches' set, as well as functions which\n                        have names assigned directly to them. The matching is\n                        case-insensitive.\n  -m MARKEXPR           Only run tests matching given mark expression. For\n                        example: -m 'mark1 and not mark2'.\n  --markers             show markers (builtin, plugin and per-project ones).\n  -x, --exitfirst       Exit instantly on first error or failed test\n  --maxfail=num         Exit after first num failures or errors\n  --strict-config       Enables the strict_config option\n  --strict-markers      Enables the strict_markers option\n  --strict              Enables the strict option\n  --fixtures, --funcargs\n                        Show available fixtures, sorted by plugin appearance\n                        (fixtures with leading '_' are only shown with '-v')\n  --fixtures-per-test   Show fixtures per test\n  --pdb                 Start the interactive Python debugger on errors or\n                        KeyboardInterrupt\n  --pdbcls=modulename:classname\n                        Specify a custom interactive Python debugger for use\n                        with --pdb.For example:\n                        --pdbcls=IPython.terminal.debugger:TerminalPdb\n  --trace               Immediately break when running each test\n  --capture=method      Per-test capturing method: one of fd|sys|no|tee-sys\n  -s                    Shortcut for --capture=no\n  --runxfail            Report the results of xfail tests as if they were not\n                        marked\n  --lf, --last-failed   Rerun only the tests that failed at the last run (or all\n                        if none failed)\n  --ff, --failed-first  Run all tests, but run the last failures first. This may\n                        re-order tests and thus lead to repeated fixture\n                        setup/teardown.\n  --nf, --new-first     Run tests from new files first, then the rest of the\n                        tests sorted by file mtime\n  --cache-show=[CACHESHOW]\n                        Show cache contents, don't perform collection or tests.\n                        Optional argument: glob (default: '*').\n  --cache-clear         Remove all cache contents at start of test run\n  --lfnf={all,none}, --last-failed-no-failures={all,none}\n                        With ``--lf``, determines whether to execute tests when\n                        there are no previously (known) failures or when no\n                        cached ``lastfailed`` data was found. ``all`` (the\n                        default) runs the full test suite again. ``none`` just\n                        emits a message about no known failures and exits\n                        successfully.\n  --sw, --stepwise      Exit on test failure and continue from last failing test\n                        next time\n  --sw-skip, --stepwise-skip\n                        Ignore the first failing test but stop on the next\n                        failing test. Implicitly enables --stepwise.\n  --sw-reset, --stepwise-reset\n                        Resets stepwise state, restarting the stepwise workflow.\n                        Implicitly enables --stepwise.\n\nReporting:\n  --durations=N         Show N slowest setup/test durations (N=0 for all)\n  --durations-min=N     Minimal duration in seconds for inclusion in slowest\n                        list. Default: 0.005 (or 0.0 if -vv is given).\n  -v, --verbose         Increase verbosity\n  --no-header           Disable header\n  --no-summary          Disable summary\n  --no-fold-skipped     Do not fold skipped tests in short summary.\n  --force-short-summary\n                        Force condensed summary output regardless of verbosity\n                        level.\n  -q, --quiet           Decrease verbosity\n  --verbosity=VERBOSE   Set verbosity. Default: 0.\n  -r chars              Show extra test summary info as specified by chars:\n                        (f)ailed, (E)rror, (s)kipped, (x)failed, (X)passed,\n                        (p)assed, (P)assed with output, (a)ll except passed\n                        (p/P), or (A)ll. (w)arnings are enabled by default (see\n                        --disable-warnings), 'N' can be used to reset the list.\n                        (default: 'fE').\n  --disable-warnings, --disable-pytest-warnings\n                        Disable warnings summary\n  -l, --showlocals      Show locals in tracebacks (disabled by default)\n  --no-showlocals       Hide locals in tracebacks (negate --showlocals passed\n                        through addopts)\n  --tb=style            Traceback print mode (auto/long/short/line/native/no)\n  --xfail-tb            Show tracebacks for xfail (as long as --tb != no)\n  --show-capture={no,stdout,stderr,log,all}\n                        Controls how captured stdout/stderr/log is shown on\n                        failed tests. Default: all.\n  --full-trace          Don't cut any tracebacks (default is to cut)\n  --color=color         Color terminal output (yes/no/auto)\n  --code-highlight={yes,no}\n                        Whether code should be highlighted (only if --color is\n                        also enabled). Default: yes.\n  --pastebin=mode       Send failed|all info to bpaste.net pastebin service\n  --junit-xml=path      Create junit-xml style report file at given path\n  --junit-prefix=str    Prepend prefix to classnames in junit-xml output\n\npytest-warnings:\n  -W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS\n                        Set which warnings to report, see -W option of Python\n                        itself\n\ncollection:\n  --collect-only, --co  Only collect tests, don't execute them\n  --pyargs              Try to interpret all arguments as Python packages\n  --ignore=path         Ignore path during collection (multi-allowed)\n  --ignore-glob=path    Ignore path pattern during collection (multi-allowed)\n  --deselect=nodeid_prefix\n                        Deselect item (via node id prefix) during collection\n                        (multi-allowed)\n  --confcutdir=dir      Only load conftest.py's relative to specified dir\n  --noconftest          Don't load any conftest.py files\n  --keep-duplicates     Keep duplicate tests\n  --collect-in-virtualenv\n                        Don't ignore tests in a local virtualenv directory\n  --continue-on-collection-errors\n                        Force test execution even if collection errors occur\n  --import-mode={prepend,append,importlib}\n                        Prepend/append to sys.path when importing test modules\n                        and conftest files. Default: prepend.\n  --doctest-modules     Run doctests in all .py modules\n  --doctest-report={none,cdiff,ndiff,udiff,only_first_failure}\n                        Choose another output format for diffs on doctest\n                        failure\n  --doctest-glob=pat    Doctests file matching pattern, default: test*.txt\n  --doctest-ignore-import-errors\n                        Ignore doctest collection errors\n  --doctest-continue-on-failure\n                        For a given doctest, continue to run after the first\n                        failure\n\ntest session debugging and configuration:\n  -c FILE, --config-file=FILE\n                        Load configuration from `FILE` instead of trying to\n                        locate one of the implicit configuration files.\n  --rootdir=ROOTDIR     Define root directory for tests. Can be relative path:\n                        'root_dir', './root_dir', 'root_dir/another_dir/';\n                        absolute path: '/home/user/root_dir'; path with\n                        variables: '$HOME/root_dir'.\n  --basetemp=dir        Base temporary directory for this test run. (Warning:\n                        this directory is removed if it exists.)\n  -V, --version         Display pytest version and information about plugins.\n                        When given twice, also display information about\n                        plugins.\n  -h, --help            Show help message and configuration info\n  -p name               Early-load given plugin module name or entry point\n                        (multi-allowed). To avoid loading of plugins, use the\n                        `no:` prefix, e.g. `no:doctest`. See also --disable-\n                        plugin-autoload.\n  --disable-plugin-autoload\n                        Disable plugin auto-loading through entry point\n                        packaging metadata. Only plugins explicitly specified in\n                        -p or env var PYTEST_PLUGINS will be loaded.\n  --trace-config        Trace considerations of conftest.py files\n  --debug=[DEBUG_FILE_NAME]\n                        Store internal tracing debug information in this log\n                        file. This file is opened with 'w' and truncated as a\n                        result, care advised. Default: pytestdebug.log.\n  -o OVERRIDE_INI, --override-ini=OVERRIDE_INI\n                        Override configuration option with \"option=value\" style,\n                        e.g. `-o strict_xfail=True -o cache_dir=cache`.\n  --assert=MODE         Control assertion debugging tools.\n                        'plain' performs no assertion debugging.\n                        'rewrite' (the default) rewrites assert statements in\n                        test modules on import to provide assert expression\n                        information.\n  --setup-only          Only setup fixtures, do not execute tests\n  --setup-show          Show setup of fixtures while executing tests\n  --setup-plan          Show what fixtures and tests would be executed but don't\n                        execute anything\n\nlogging:\n  --log-level=LEVEL     Level of messages to catch/display. Not set by default,\n                        so it depends on the root/parent log handler's effective\n                        level, where it is \"WARNING\" by default.\n  --log-format=LOG_FORMAT\n                        Log format used by the logging module\n  --log-date-format=LOG_DATE_FORMAT\n                        Log date format used by the logging module\n  --log-cli-level=LOG_CLI_LEVEL\n                        CLI logging level\n  --log-cli-format=LOG_CLI_FORMAT\n                        Log format used by the logging module\n  --log-cli-date-format=LOG_CLI_DATE_FORMAT\n                        Log date format used by the logging module\n  --log-file=LOG_FILE   Path to a file when logging will be written to\n  --log-file-mode={w,a}\n                        Log file open mode\n  --log-file-level=LOG_FILE_LEVEL\n                        Log file logging level\n  --log-file-format=LOG_FILE_FORMAT\n                        Log format used by the logging module\n  --log-file-date-format=LOG_FILE_DATE_FORMAT\n                        Log date format used by the logging module\n  --log-auto-indent=LOG_AUTO_INDENT\n                        Auto-indent multiline messages passed to the logging\n                        module. Accepts true|on, false|off or an integer.\n  --log-disable=LOGGER_DISABLE\n                        Disable a logger by name. Can be passed multiple times.\n\ncoverage reporting with distributed testing support:\n  --cov=[SOURCE]        Path or package name to measure during execution (multi-\n                        allowed). Use --cov= to not do any source filtering and\n                        record everything.\n  --cov-reset           Reset cov sources accumulated in options so far.\n  --cov-report=TYPE     Type of report to generate: term, term-missing,\n                        annotate, html, xml, json, markdown, markdown-append,\n                        lcov (multi-allowed). term, term-missing may be followed\n                        by \":skip-covered\". annotate, html, xml, json, markdown,\n                        markdown-append and lcov may be followed by \":DEST\"\n                        where DEST specifies the output location. Use --cov-\n                        report= to not generate any output.\n  --cov-config=PATH     Config file for coverage. Default: .coveragerc\n  --no-cov-on-fail      Do not report coverage if test run fails. Default: False\n  --no-cov              Disable coverage report completely (useful for\n                        debuggers). Default: False\n  --cov-fail-under=MIN  Fail if the total coverage is less than MIN.\n  --cov-append          Do not delete coverage but append to current. Default:\n                        False\n  --cov-branch          Enable branch coverage.\n  --cov-precision=COV_PRECISION\n                        Override the reporting precision.\n  --cov-context=CONTEXT\n                        Dynamic contexts to use. \"test\" for now.\n\n[pytest] configuration options in the first pytest.toml|pytest.ini|tox.ini|setup.cfg|pyproject.toml file found:\n\n  markers (linelist):   Register new markers for test functions\n  empty_parameter_set_mark (string):\n                        Default marker for empty parametersets\n  strict_config (bool): Any warnings encountered while parsing the `pytest`\n                        section of the configuration file raise errors\n  strict_markers (bool):\n                        Markers not registered in the `markers` section of the\n                        configuration file raise errors\n  strict (bool):        Enables all strictness options, currently:\n                        strict_config, strict_markers, strict_xfail,\n                        strict_parametrization_ids\n  filterwarnings (linelist):\n                        Each line specifies a pattern for\n                        warnings.filterwarnings. Processed after\n                        -W/--pythonwarnings.\n  norecursedirs (args): Directory patterns to avoid for recursion\n  testpaths (args):     Directories to search for tests when no files or\n                        directories are given on the command line\n  collect_imported_tests (bool):\n                        Whether to collect tests in imported modules outside\n                        `testpaths`\n  consider_namespace_packages (bool):\n                        Consider namespace packages when resolving module names\n                        during import\n  usefixtures (args):   List of default fixtures to be used with this project\n  python_files (args):  Glob-style file patterns for Python test module\n                        discovery\n  python_classes (args):\n                        Prefixes or glob names for Python test class discovery\n  python_functions (args):\n                        Prefixes or glob names for Python test function and\n                        method discovery\n  disable_test_id_escaping_and_forfeit_all_rights_to_community_support (bool):\n                        Disable string escape non-ASCII characters, might cause\n                        unwanted side effects(use at your own risk)\n  strict_parametrization_ids (bool):\n                        Emit an error if non-unique parameter set IDs are\n                        detected\n  console_output_style (string):\n                        Console output: \"classic\", or with additional progress\n                        information (\"progress\" (percentage) | \"count\" |\n                        \"progress-even-when-capture-no\" (forces progress even\n                        when capture=no)\n  verbosity_test_cases (string):\n                        Specify a verbosity level for test case execution,\n                        overriding the main level. Higher levels will provide\n                        more detailed information about each test case executed.\n  strict_xfail (bool):  Default for the strict parameter of xfail markers when\n                        not given explicitly (default: False) (alias:\n                        xfail_strict)\n  tmp_path_retention_count (string):\n                        How many sessions should we keep the `tmp_path`\n                        directories, according to `tmp_path_retention_policy`.\n  tmp_path_retention_policy (string):\n                        Controls which directories created by the `tmp_path`\n                        fixture are kept around, based on test outcome.\n                        (all/failed/none)\n  enable_assertion_pass_hook (bool):\n                        Enables the pytest_assertion_pass hook. Make sure to\n                        delete any previously generated pyc cache files.\n  truncation_limit_lines (string):\n                        Set threshold of LINES after which truncation will take\n                        effect\n  truncation_limit_chars (string):\n                        Set threshold of CHARS after which truncation will take\n                        effect\n  verbosity_assertions (string):\n                        Specify a verbosity level for assertions, overriding the\n                        main level. Higher levels will provide more detailed\n                        explanation when an assertion fails.\n  junit_suite_name (string):\n                        Test suite name for JUnit report\n  junit_logging (string):\n                        Write captured log messages to JUnit report: one of\n                        no|log|system-out|system-err|out-err|all\n  junit_log_passing_tests (bool):\n                        Capture log information for passing tests to JUnit\n                        report:\n  junit_duration_report (string):\n                        Duration time to report: one of total|call\n  junit_family (string):\n                        Emit XML for schema: one of legacy|xunit1|xunit2\n  doctest_optionflags (args):\n                        Option flags for doctests\n  doctest_encoding (string):\n                        Encoding used for doctest files\n  cache_dir (string):   Cache directory path\n  log_level (string):   Default value for --log-level\n  log_format (string):  Default value for --log-format\n  log_date_format (string):\n                        Default value for --log-date-format\n  log_cli (bool):       Enable log display during test run (also known as \"live\n                        logging\")\n  log_cli_level (string):\n                        Default value for --log-cli-level\n  log_cli_format (string):\n                        Default value for --log-cli-format\n  log_cli_date_format (string):\n                        Default value for --log-cli-date-format\n  log_file (string):    Default value for --log-file\n  log_file_mode (string):\n                        Default value for --log-file-mode\n  log_file_level (string):\n                        Default value for --log-file-level\n  log_file_format (string):\n                        Default value for --log-file-format\n  log_file_date_format (string):\n                        Default value for --log-file-date-format\n  log_auto_indent (string):\n                        Default value for --log-auto-indent\n  faulthandler_timeout (string):\n                        Dump the traceback of all threads if a test takes more\n                        than TIMEOUT seconds to finish\n  faulthandler_exit_on_timeout (bool):\n                        Exit the test process if a test takes more than\n                        faulthandler_timeout seconds to finish\n  verbosity_subtests (string):\n                        Specify verbosity level for subtests. Higher levels will\n                        generate output for passed subtests. Failed subtests are\n                        always reported.\n  addopts (args):       Extra command line options\n  minversion (string):  Minimally required pytest version\n  pythonpath (paths):   Add paths to sys.path\n  required_plugins (args):\n                        Plugins that must be present for pytest to run\n  anyio_mode (string):  AnyIO plugin mode (either \"strict\" or \"auto\")\n\nEnvironment variables:\n  CI                       When set to a non-empty value, pytest knows it is running in a CI process and does not truncate summary info\n  BUILD_NUMBER             Equivalent to CI\n  PYTEST_ADDOPTS           Extra command line options\n  PYTEST_PLUGINS           Comma-separated plugins to load during startup\n  PYTEST_DISABLE_PLUGIN_AUTOLOAD Set to disable plugin auto-loading\n  PYTEST_DEBUG             Set to enable debug tracing of pytest's internals\n  PYTEST_DEBUG_TEMPROOT    Override the system temporary directory\n  PYTEST_THEME             The Pygments style to use for code output\n  PYTEST_THEME_MODE        Set the PYTEST_THEME to be either 'dark' or 'light'\n\n\nto see available markers type: pytest --markers\nto see available fixtures type: pytest --fixtures\n(shown according to specified file_or_dir or current dir if not specified; fixtures with leading '_' are only shown with the '-v' option\n",
  "fingerprint": null,
  "meta": {
    "os": "Linux",
    "python_version": "3.11.2"
  }
}