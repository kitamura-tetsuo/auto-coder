---
# Auto-Coder Client Features Documentation
# This file documents all features implemented in the Auto-Coder application

application:
  name: "Auto-Coder"
  version: "2025.10.14+gf0f5853"
  description: "Automated application development using AI CLI backends (codex default, switchable to gemini via --backend) and GitHub integration"

features:
  github_integration:
    name: "GitHub API Integration"
    description: "Integration with GitHub API to fetch and manage issues and pull requests"
    components:
      - name: "GitHubClient"
        file: "src/auto_coder/github_client.py"
        methods:
          - name: "get_repository"
            description: "Retrieve repository object by name"
            parameters: ["repo_name"]
            returns: "Repository object"
          - name: "get_open_issues"
            description: "Fetch open issues from repository, sorted by creation date (oldest first)"
            parameters: ["repo_name", "limit"]
            returns: "List of Issue objects"
          - name: "get_open_pull_requests"
            description: "Fetch open pull requests from repository, sorted by creation date (oldest first)"
            parameters: ["repo_name", "limit"]
            returns: "List of PullRequest objects"
          - name: "get_issue_details"
            description: "Extract detailed information from an issue"
            parameters: ["issue"]
            returns: "Dictionary with issue details"
          - name: "get_pr_details"
            description: "Extract detailed information from a pull request"
            parameters: ["pr"]
            returns: "Dictionary with PR details"
          - name: "get_pr_details_by_number"
            description: "Get PR details by repository name and PR number"
            parameters: ["repo_name", "pr_number"]
            returns: "Dictionary with PR details"
          - name: "get_issue_details_by_number"
            description: "Get Issue details by repository name and issue number"
            parameters: ["repo_name", "issue_number"]
            returns: "Dictionary with Issue details"
          - name: "create_issue"
            description: "Create a new issue in the repository"
            parameters: ["repo_name", "title", "body", "labels"]
            returns: "Issue object"
          - name: "add_comment_to_issue"
            description: "Add a comment to an existing issue"
            parameters: ["repo_name", "issue_number", "comment"]
            returns: "None"
          - name: "close_issue"
            description: "Close an issue with optional comment"
            parameters: ["repo_name", "issue_number", "comment"]
            returns: "None"
          - name: "add_labels_to_issue"
            description: "Add labels to an existing issue (avoids duplicates)"
            parameters: ["repo_name", "issue_number", "labels"]
            returns: "None"
          - name: "remove_labels_from_issue"
            description: "Remove labels from an existing issue"
            parameters: ["repo_name", "issue_number", "labels"]
            returns: "None"
          - name: "has_label"
            description: "Check if an issue has a specific label"
            parameters: ["repo_name", "issue_number", "label"]
            returns: "Boolean indicating if the label exists"
          - name: "try_add_work_in_progress_label"
            description: "Try to add work-in-progress label (@auto-coder) to an issue/PR for exclusive processing"
            parameters: ["repo_name", "issue_number", "label (default: @auto-coder)"]
            returns: "Boolean - True if label was added (not being processed), False if label already exists (being processed)"
            behavior:
              - "Checks if @auto-coder label already exists on the issue/PR"
              - "Returns False if label exists (indicates another instance is processing)"
              - "Adds label and returns True if label doesn't exist"
              - "Provides basic exclusive processing control"
            tests:
              - "tests/test_exclusive_processing_label.py::TestGitHubClientExclusiveLabels::test_try_add_work_in_progress_label_success"
              - "tests/test_exclusive_processing_label.py::TestGitHubClientExclusiveLabels::test_try_add_work_in_progress_label_already_exists"
              - "tests/test_exclusive_processing_label.py::TestGitHubClientExclusiveLabels::test_remove_labels_from_issue"
              - "tests/test_exclusive_processing_label.py::TestGitHubClientExclusiveLabels::test_has_label_true"
              - "tests/test_exclusive_processing_label.py::TestGitHubClientExclusiveLabels::test_has_label_false"
          - name: "get_linked_prs_via_graphql"
            description: "Get linked PRs for an issue using GitHub GraphQL API (Development section)"
            parameters: ["repo_name", "issue_number"]
            returns: "List of PR numbers linked to the issue"
            behavior:
              - "Uses gh CLI to query GraphQL API for ConnectedEvent timeline items"
              - "Returns only OPEN PRs that are linked in the Development section"
              - "Returns empty list on errors (graceful degradation)"
            implementation:
              - "Queries repository.issue.timelineItems with CONNECTED_EVENT filter"
              - "Extracts PR numbers from source.number where state is OPEN"
          - name: "has_linked_pr"
            description: "Check if an issue has a linked pull request (GraphQL + text search fallback)"
            parameters: ["repo_name", "issue_number"]
            returns: "Boolean indicating if a linked PR exists"
            behavior:
              - "First tries GraphQL API to check Development section (most accurate)"
              - "Falls back to searching PR titles/bodies for issue references"
              - "Detects patterns: #123, fixes #123, closes #123, resolves #123, issue #123"
              - "Returns True if any open PR references the issue"
              - "Returns False on exceptions (graceful degradation)"
            tests:
              - "tests/test_github_client.py::TestGitHubClient::test_get_linked_prs_via_graphql_success"
              - "tests/test_github_client.py::TestGitHubClient::test_get_linked_prs_via_graphql_no_linked_prs"
              - "tests/test_github_client.py::TestGitHubClient::test_get_linked_prs_via_graphql_handles_error"
              - "tests/test_github_client.py::TestGitHubClient::test_has_linked_pr_uses_graphql_first"
              - "tests/test_github_client.py::TestGitHubClient::test_has_linked_pr_with_linked_pr"
              - "tests/test_github_client.py::TestGitHubClient::test_has_linked_pr_with_no_linked_pr"
              - "tests/test_github_client.py::TestGitHubClient::test_has_linked_pr_with_multiple_patterns"
              - "tests/test_github_client.py::TestGitHubClient::test_has_linked_pr_handles_exception"

  gemini_integration:
    name: "Gemini AI Integration"
    description: "Integration with Gemini AI for single-run direct actions (no analysis-only calls)"
    components:
      - name: "GeminiClient"
        file: "src/auto_coder/gemini_client.py"
        methods:
          - name: "suggest_features"
            description: "Suggest new features based on repository analysis"
            parameters: ["repo_context"]
            returns: "List of feature suggestions"
          - name: "switch_to_conflict_model"
            description: "Switch to faster model (gemini-2.5-flash) for conflict resolution"
            parameters: []
            returns: "None"
          - name: "switch_to_default_model"
            description: "Switch back to default model"
            parameters: []
            returns: "None"
          - name: "_escape_prompt"
            description: "Escape @ characters in prompts for safe Gemini CLI usage"
            parameters: ["prompt"]
            returns: "String with escaped @ characters"

  codex_mcp_integration:
    name: "Codex MCP Integration"
    description: "Integration with Codex MCP server maintaining a persistent session during a single PR or a single error-fix flow. Implements minimal JSON-RPC handshake (initialize) and a tools/call echo invocation; falls back to codex exec when unavailable."
    components:
      - name: "CodexMCPClient"
        file: "src/auto_coder/codex_mcp_client.py"
        details: |
          - Spawns persistent MCP subprocess (default: `codex mcp`)
          - Performs JSON-RPC initialize handshake
          - Attempts `tools/call` with an `echo` tool first; if not supported, falls back to `codex exec` with session kept alive
          - Environment overrides for testing:
            - AUTOCODER_CODEX_CLI: overrides CLI check command (default: `codex`)
            - AUTOCODER_MCP_COMMAND: overrides MCP subprocess command (default: `codex mcp`)
            - AUTOCODER_MCP_TIMEOUT / AUTOCODER_MCP_HANDSHAKE_TIMEOUT: configure select-based read timeouts to prevent MCP hangs during handshake and requests
        methods:
          - name: "_run_gemini_cli"
            description: "Prefer MCP tools/call (echo) then fallback to codex exec while MCP session stays alive"
            parameters: ["prompt"]
            returns: "String output"
          - name: "close"
            description: "Terminate the persistent MCP subprocess if running"
            parameters: []
            returns: "None"

  automation_engine:
    name: "Automation Engine"
    description: "Main orchestration engine that coordinates GitHub and LLM integration"
    components:
      - name: "AutomationEngine"
        file: "src/auto_coder/automation_engine.py"
        methods:
          - name: "run"
            description: "Execute the main automation process for a repository"
            parameters: ["repo_name", "jules_mode (optional)"]
            returns: "Dictionary with automation results including llm_backend and llm_model"
            report_fields:
              - "repository: Repository name"
              - "timestamp: ISO format timestamp"
              - "dry_run: Boolean indicating dry run mode"
              - "jules_mode: Boolean indicating Jules mode"
              - "llm_backend: LLM backend used (e.g., 'codex', 'gemini', 'qwen', 'auggie')"
              - "llm_model: LLM model name used"
              - "issues_processed: List of processed issues (analysis/solution fields removed)"
              - "prs_processed: List of processed PRs"
              - "errors: List of errors encountered"
          - name: "_get_llm_backend_info"
            description: "Get LLM backend and model information from the LLM client"
            parameters: []
            returns: "Dictionary with 'backend' and 'model' keys"
            behavior:
              - "If llm client is None, returns {backend: None, model: None}"
              - "If llm client has get_last_backend_and_model method (BackendManager), uses it"
              - "Otherwise, infers backend from class name and gets model_name attribute"
          - name: "_save_report"
            description: "Save automation report to file. When repo_name is provided, saves to ~/.auto-coder/{repository}/ instead of reports/"
            parameters: ["data", "filename", "repo_name (optional)"]
            returns: "None"
            behavior:
              - "If repo_name is provided, saves to ~/.auto-coder/{repository}/"
              - "If repo_name is not provided, saves to reports/ (legacy behavior)"
              - "Filename format: {filename}_{timestamp}.json"
              - "Repository name is excluded from filename (directory distinguishes repos)"
          - name: "fix_to_pass_tests"
            description: "Run local tests and iteratively request LLM fixes until tests pass; commits are gated and happen only when the test output or the LLM error summary changes by >=10%; at the beginning of each iteration the loop checks for Auto-Coder updates and restarts with the original CLI arguments when an upgrade is applied; errors if LLM makes no edits"
            parameters: ["max_attempts (optional)"]
            returns: "Dictionary with success, attempts, and messages"
          - name: "process_single"
            description: "Process a single issue or PR by number; supports 'auto' detection when number is given"
            parameters: ["repo_name", "target_type ('issue'|'pr'|'auto')", "number", "jules_mode (optional)"]
            returns: "Dictionary with results for the single target"
          - name: "create_feature_issues"
            description: "Analyze repository and create feature enhancement issues"
            parameters: ["repo_name"]
            returns: "List of created issues"
          - name: "_process_issues"
            description: "Process open issues in the repository"
            parameters: ["repo_name"]
            returns: "List of processed issues"
          - name: "_process_issues_jules_mode"
            description: "Process open issues in jules mode - only add 'jules' label"
            parameters: ["repo_name"]
            returns: "List of processed issues"
          - name: "_process_pull_requests"
            description: "Process open pull requests in the repository with two-loop priority order, checking for Auto-Coder updates at the start of each iteration and restarting with the recorded CLI arguments when an upgrade is applied"
            parameters: ["repo_name"]
            returns: "List of processed PRs"
            details: "First loop merges PRs with passing Actions AND mergeable status, second loop fixes remaining PRs; each pass re-runs the auto-update check before contacting GitHub so upgrades are applied before continuing"
          - name: "_take_issue_actions"
            description: "Take automated actions based on issue analysis"
            parameters: ["repo_name", "issue_data", "analysis", "solution"]
            returns: "List of actions taken"
          - name: "_take_pr_actions"
            description: "Take automated actions based on PR analysis"
            parameters: ["repo_name", "pr_data", "analysis"]
            returns: "List of actions taken"
          - name: "_process_pr_for_merge"
            description: "Process a PR for quick merging when GitHub Actions are passing"
            parameters: ["repo_name", "pr_data"]
            returns: "Dictionary with PR processing results"
          - name: "_process_pr_for_fixes"
            description: "Process a PR for issue resolution when GitHub Actions are failing or pending"
            parameters: ["repo_name", "pr_data"]
            returns: "Dictionary with PR processing results"
          - name: "_fix_pr_issues_with_testing"
            description: "Fix PR issues by applying GitHub Actions log guidance then iterating local tests; every loop iteration begins with an auto-update check that restarts with the saved CLI arguments when an upgrade is detected"
            parameters: ["repo_name", "pr_data", "config", "dry_run", "github_logs"]
            returns: "List of actions taken"
          - name: "_is_package_lock_only_conflict"
            description: "Check if merge conflicts are only in package-lock.json or similar dependency files"
            parameters: ["conflict_info"]
            returns: "Boolean indicating if conflicts are dependency-file only"
          - name: "_resolve_package_lock_conflicts"
            description: "Resolve package-lock.json conflicts by deleting and regenerating dependency files"
            parameters: ["pr_data", "conflict_info"]
            returns: "List of actions taken during resolution"
          - name: "_get_github_actions_logs"
            description: "Use gh api to fetch failed job logs (ZIP) for the latest failed run on the PR branch and extract error snippets. Detect failing steps and extract Playwright-style failure blocks including expectation details. Fallback to gh run view --job --log when ZIP is unavailable."
            parameters: ["repo_name", "pr_data", "failed_checks"]
            returns: "String containing extracted error snippets per failed job (with step headings and expectation details when available)"


  command_execution:
    name: "Command Execution"
    description: "Unified command runner with debugger-friendly streaming mode"
    components:
      - name: "CommandExecutor.run_command"
        file: "src/auto_coder/utils.py"
        description: |
          Executes shell commands with consistent timeout handling and optional streaming.
          Automatically streams stdout/stderr when a debugger is attached or when AUTOCODER_STREAM_COMMANDS=1.
          Recognizes common debug adapters (debugpy, VS Code, PyCharm) via environment markers to ensure streaming during IDE sessions.
          Uses background reader threads plus short-interval polling so debugger pauses land within a few hundred milliseconds even when the command is silent.
          Consumed by Codex/Gemini/Qwen CLI clients for LLM invocations via CommandExecutor.run_command(..., stream_output=True).
          Preserves captured output for downstream processing while logging live updates for active debugging.
        parameters:
          - "cmd: list[str]"
          - "timeout: Optional[int]"
          - "cwd: Optional[str]"
          - "check_success: bool"
          - "stream_output: Optional[bool]"
          - "env: Optional[dict[str, str]]"
        returns: "CommandResult(success, stdout, stderr, returncode)"
        tests:
          - "tests/test_utils_command_executor.py::test_run_command_respects_stream_flag"
          - "tests/test_utils_command_executor.py::test_run_command_streams_output"
          - "tests/test_utils_command_executor.py::test_should_stream_when_debugger_attached"
          - "tests/test_utils_command_executor.py::test_should_stream_when_env_forced"
          - "tests/test_utils_command_executor.py::test_should_stream_for_debugger_markers"
          - "tests/test_llm_cli_neutral.py::test_codex_client_run_llm_cli_delegates"
          - "tests/test_llm_cli_neutral.py::test_gemini_client_run_llm_cli_delegates"
          - "tests/test_llm_cli_neutral.py::test_qwen_client_run_llm_cli_delegates"
  test_runner_utils:
    name: "Test Runner Utilities"
    description: "Utilities to parse test outputs and assist selective re-runs"
    components:
      - name: "extract_first_failed_test"
        file: "src/auto_coder/utils.py"
        description: "Robustly extracts the first failed test file from stdout/stderr across pytest and Playwright formats"
        inputs:
          - "stdout: string"
          - "stderr: string"
        returns: "Relative file path to the first failed test or null"
        supports:
          - "pytest summary lines: 'FAILED tests/test_foo.py::test_bar - ...'"
          - "pytest traceback lines: 'tests/test_foo.py:12: in test_bar'"
          - "Playwright specs: 'e2e/.../name.spec.ts:16:5'"
        tests:
          - "tests/test_utils_extract_first_failed_test.py::test_extract_from_pytest_failed_summary_hyphen"
          - "tests/test_utils_extract_first_failed_test.py::test_extract_from_pytest_traceback_line"
          - "tests/test_utils_extract_first_failed_test.py::test_extract_from_playwright_spec"
      - name: "change_fraction"
        file: "src/auto_coder/utils.py"
        description: "Compute fraction of change using only the tail window (min of last 20 lines or last 1000 chars) for performance; returns 1 - difflib ratio on the selected windows. None is treated as empty, equal strings return 0.0."
        tests:
          - "tests/test_utils_change_fraction.py::test_change_fraction_ignores_large_prefix_when_last_20_lines_identical"
          - "tests/test_utils_change_fraction.py::test_change_fraction_ignores_large_prefix_when_last_1000_chars_identical"
          - "tests/test_utils_change_fraction.py::test_change_fraction_detects_tail_difference"
          - "tests/test_utils_change_fraction.py::test_change_fraction_none_and_equal_cases"

      - name: "run_local_tests"
        file: "src/auto_coder/fix_to_pass_tests_runner.py"
        description: |
          Executes local tests via TEST_SCRIPT_PATH (scripts/test.sh) with no pytest fallback.
          Behavior:
          - When a specific test file is provided, invokes: `bash $TEST_SCRIPT_PATH <file>`
          - When running all tests via script and failures occur, extracts the first failed test and re-runs it via script with the file argument
          - TEST_SCRIPT_PATH is validated once at CLI startup; if missing, the command errors and exits
        tests:
          - "tests/test_run_local_tests_script.py::test_run_local_tests_uses_script_for_single_file"
          - "tests/test_run_local_tests_script.py::test_run_local_tests_uses_script_for_all_tests"
          - "tests/test_run_local_tests_script.py::test_run_local_tests_reruns_first_failed_via_script"


  cli_interface:
    name: "Command Line Interface"
    description: "CLI for interacting with Auto-Coder functionality"
    components:
      - name: "CLI Commands"
        file: "src/auto_coder/cli.py"
        commands:
          - name: "process-issues"
            description: "Process GitHub issues and PRs using AI CLI (codex or gemini)"
            options:
              - "--repo": "GitHub repository (owner/repo)"
              - "--github-token": "GitHub API token"
              - "--backend": "AI backend(s) to use (codex|codex-mcp|gemini|qwen|auggie). Repeat option to set fallbacks; first value becomes the default. Default: codex"
              - "--model-gemini": "Model to use when backend=gemini"
              - "--model-qwen": "Model to use when backend=qwen"
              - "--model-auggie": "Model to use when backend=auggie (defaults to GPT-5)"
              - "--dry-run": "Run in dry-run mode without making changes"
              - "--jules-mode": "Run in jules mode - only add 'jules' label to issues (PRs still use AI analysis)"
              - "--skip-main-update/--no-skip-main-update": "When PR checks fail, skip merging main into PR before attempting fixes (default: skip)"
              - "--ignore-dependabot-prs/--no-ignore-dependabot-prs": "Ignore PRs opened by Dependabot when processing PRs (default: do not ignore)"
              - "--only": "Process only a specific issue/PR by URL or number (e.g., https://github.com/owner/repo/issues/123 or 123)"
              - "--log-level": "Set logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)"
              - "--log-file": "Log file path (optional)"
          - name: "create-feature-issues"
            description: "Analyze repository and create feature enhancement issues"
            options:
              - "--repo": "GitHub repository (owner/repo)"
              - "--github-token": "GitHub API token"
              - "--backend": "AI backend(s) to use (codex|codex-mcp|gemini|qwen|auggie). Repeat option to set fallbacks; first value becomes the default. Default: codex"
              - "--model-gemini": "Model to use when backend=gemini"
              - "--model-qwen": "Model to use when backend=qwen"
              - "--model-auggie": "Model to use when backend=auggie (defaults to GPT-5)"
              - "--gemini-api-key": "Gemini API key (optional, used when backend=gemini)"
          - name: "fix-to-pass-tests"
            description: "Run tests and request LLM fixes until passing; automatically checks for Auto-Coder updates at the start of each LLM attempt and restarts with the original CLI flags when an upgrade completes; stop with error if LLM made no edits"
            options:
              - "--backend": "AI backend(s) to use (codex|codex-mcp|gemini|qwen|auggie). Repeat option to set fallbacks; first value becomes the default. Default: codex"
              - "--model-gemini": "Model to use when backend=gemini"
              - "--model-qwen": "Model to use when backend=qwen"
              - "--model-auggie": "Model to use when backend=auggie (defaults to GPT-5)"
              - "--gemini-api-key": "Gemini API key (optional, used when backend=gemini)"
              - "--max-attempts": "Maximum fix attempts before giving up (defaults to engine config)"
              - "--dry-run": "Run without making changes"
              - "--log-level": "Set logging level"
              - "--log-file": "Log file path"
          - name: "mcp-pdb"
            description: "Helpers to set up and verify mcp-pdb (Model Context Protocol PDB server)"
            options:
              - "print-config --target [windsurf|claude]": "Print configuration snippet for Windsurf or Claude; optionally write to file"
              - "status": "Check prerequisites (uv availability) and show setup tips"


  configuration:
    name: "Configuration Management"
    description: "Application configuration and settings management"
    components:
      - name: "AutomationConfig"
        file: "src/auto_coder/automation_config.py"
        methods:
          - name: "get_reports_dir"
            description: "Get the reports directory for a specific repository"
            parameters: ["repo_name"]
            returns: "Path to ~/.auto-coder/{repository}/"
            behavior:
              - "Converts repo_name (e.g., 'owner/repo') to safe directory name (e.g., 'owner_repo')"
              - "Returns path: ~/.auto-coder/{safe_repo_name}/"
      - name: "Settings"
        file: "src/auto_coder/config.py"
        settings:
          - name: "github_token"
            description: "GitHub API token"
            env_var: "GITHUB_TOKEN"
            default: null
          - name: "github_api_url"
            description: "GitHub API URL"
            env_var: "GITHUB_API_URL"
            default: "https://api.github.com"
          - name: "gemini_api_key"
            description: "Gemini API key"
            env_var: "GEMINI_API_KEY"
            default: null
          - name: "gemini_model"
            description: "Gemini model to use"
            env_var: "GEMINI_MODEL"
            default: "gemini-pro"
          - name: "max_issues_per_run"
            description: "Maximum issues to process per run"
            env_var: "MAX_ISSUES_PER_RUN"
            default: 10
          - name: "max_prs_per_run"
            description: "Maximum PRs to process per run"
            env_var: "MAX_PRS_PER_RUN"
            default: 5
          - name: "dry_run"
            description: "Enable dry-run mode"
            env_var: "DRY_RUN"
            default: false

workflows:
  issue_processing:
    name: "Issue Processing Workflow"
    description: "Automated workflow for processing GitHub issues (single-run, no analysis phase) with exclusive processing control"
    steps:
      1. "Fetch open issues from repository (oldest first)"
      2. "Try to add @auto-coder label to issue for exclusive processing"
      3. "Skip if @auto-coder label already exists (being processed by another instance)"
      4. "Check if issue has a linked PR (via GraphQL Development section or text search)"
      5. "Skip issues that already have linked PRs to avoid duplicate work"
      6. "Switch to appropriate branch: PR head_branch if present, otherwise default branch"
      7. "Take direct actions via AI CLI in a single run (analysis+implementation combined)"
      8. "Add comments or close issues as appropriate"
      9. "Remove @auto-coder label after processing (success or error)"
      10. "Generate automation report"
    exclusive_processing:
      - "Uses @auto-coder label as work-in-progress flag"
      - "Label is added at start of processing"
      - "Label is removed after processing completes or on error"
      - "Provides basic protection against concurrent processing"
    tests:
      - "tests/test_issue_processor_skip_linked.py::TestIssueProcessorSkipLinked::test_process_issues_normal_skips_issue_with_linked_pr"
      - "tests/test_issue_processor_skip_linked.py::TestIssueProcessorSkipLinked::test_process_issues_normal_processes_all_when_no_linked_prs"
      - "tests/test_issue_processor_skip_linked.py::TestIssueProcessorSkipLinked::test_process_issues_normal_skips_all_when_all_have_linked_prs"
      - "tests/test_issue_processor_skip_linked.py::TestIssueProcessorSkipLinked::test_process_issues_normal_handles_has_linked_pr_exception"
      - "tests/test_exclusive_processing_label.py::TestIssueProcessorExclusiveProcessing::test_process_issues_normal_skips_when_label_exists"
      - "tests/test_exclusive_processing_label.py::TestIssueProcessorExclusiveProcessing::test_process_issues_normal_processes_when_label_added"
      - "tests/test_exclusive_processing_label.py::TestIssueProcessorExclusiveProcessing::test_process_issues_normal_removes_label_on_error"
      - "tests/test_exclusive_processing_label.py::TestIssueProcessorExclusiveProcessing::test_process_issues_jules_mode_skips_when_label_exists"

  pr_processing:
    name: "Pull Request Processing Workflow"
    description: "Automated workflow for processing GitHub pull requests with two-loop priority order and exclusive processing control"
    steps:
      1. "Fetch open pull requests from repository (oldest first)"
      2. "At the beginning of each pass iteration, check for Auto-Coder updates and restart with the original CLI arguments when an upgrade is applied"
      3. "First loop: Try to add @auto-coder label, skip if already exists, check GitHub Actions status AND mergeable status, merge qualifying PRs, remove @auto-coder label"
      4. "Second loop: Try to add @auto-coder label, skip if already exists or already handled, process remaining PRs for issue resolution, remove @auto-coder label"
      5. "Generate automation report"
    exclusive_processing:
      - "Uses @auto-coder label as work-in-progress flag"
      - "Label is added at start of processing in each loop"
      - "Label is removed after processing completes or on error"
      - "Provides basic protection against concurrent processing"
    tests:
      - "tests/test_exclusive_processing_label.py::TestPRProcessorExclusiveProcessing::test_process_pull_requests_skips_when_label_exists"

  feature_suggestion:
    name: "Feature Suggestion Workflow"
    description: "Automated workflow for suggesting and creating feature issues"
    steps:
      1. "Analyze repository context"
      2. "Generate feature suggestions using Gemini AI"
      3. "Create feature issues in repository"
      4. "Generate feature suggestions report"

  jules_mode:
    name: "Jules Mode Workflow"
    description: "Jules mode - simple label addition for issues; PRs processed without analysis-only phase, with exclusive processing control"
    steps:
      1. "Fetch open issues from repository (oldest first)"
      2. "Try to add @auto-coder label to issue for exclusive processing"
      3. "Skip if @auto-coder label already exists (being processed by another instance)"
      4. "Check if 'jules' label already exists on each issue"
      5. "Add 'jules' label to issues that don't have it"
      6. "Remove @auto-coder label after processing"
      7. "Process PRs with single-run direct actions (no analysis-only phase)"
      8. "Generate automation report"
    exclusive_processing:
      - "Uses @auto-coder label as work-in-progress flag"
      - "Label is added at start of processing"
      - "Label is removed after processing completes or on error"
      - "Provides basic protection against concurrent processing"

special_features:
  prompt_escaping:
    name: "Gemini Prompt @ Character Escaping"
    description: "Automatically escapes @ characters in prompts to prevent Gemini CLI parsing issues"
    behavior:
      - "Detects @ characters in prompts before sending to Gemini CLI"
      - "Replaces @ with \\@ to prevent CLI argument parsing conflicts"
      - "Ensures safe transmission of user mentions and email addresses in prompts"
    benefits:
      - "Prevents CLI parsing errors with @ characters"
      - "Allows safe inclusion of user mentions and email addresses"
      - "Maintains prompt integrity during Gemini CLI communication"
    implementation:
      - "Applied automatically in _run_gemini_cli method"
      - "Uses simple string replacement: @ → \\@"
      - "No user intervention required"

  enhanced_pr_merge_criteria:
    name: "Enhanced PR Merge Criteria"
    description: "Improved first-loop PR processing with both GitHub Actions success AND mergeable status checks"
    behavior:
      - "First loop only processes PRs that have BOTH passing GitHub Actions AND mergeable status"
      - "PRs with passing Actions but not mergeable are deferred to second loop"
      - "PRs with mergeable status but failing Actions are deferred to second loop"
      - "Only PRs meeting both criteria are processed for immediate merge"
    benefits:
      - "Reduces merge failures by checking mergeable status upfront"
      - "Prevents wasted processing time on unmergeable PRs"
      - "Improves automation reliability and success rate"
    criteria:
      - "GitHub Actions: success = true"
      - "PR mergeable: mergeable = true"
      - "Both conditions must be met for first-loop processing"

  conflict_resolution:
    name: "Automatic Model Switching for Conflicts"
    description: "Automatically switches to faster model (gemini-2.5-flash) when resolving PR merge conflicts"
    behavior:
      - "Detects merge conflicts in PRs"
      - "Switches from default model to gemini-2.5-flash for faster conflict resolution"
      - "Resolves conflicts using AI analysis"
      - "Switches back to default model after resolution"
    benefits:
      - "Faster conflict resolution with optimized model"
      - "Cost-effective processing for conflict scenarios"
      - "Maintains quality while improving speed"

  package_lock_conflict_resolution:
    name: "Specialized Package Lock Conflict Resolution"
    description: "Automatically resolves package-lock.json conflicts by regenerating dependency files"
    behavior:
      - "Detects conflicts that only affect package-lock.json, yarn.lock, or pnpm-lock.yaml"
      - "Removes conflicted dependency lock files"
      - "Runs appropriate package manager (npm install, yarn install) to regenerate lock files"
      - "Commits and pushes the resolved changes"
      - "Bypasses AI analysis for faster resolution"
    benefits:
      - "Instant resolution of common dependency conflicts"
      - "No manual intervention required"
      - "Maintains dependency integrity"
      - "Faster than AI-based conflict resolution"
    supported_files:
      - "package-lock.json"
      - "yarn.lock"
      - "pnpm-lock.yaml"

  package_json_dependency_conflict_resolution:
    name: "package.json Dependency-only Conflict Resolver"
    description: "When conflicts in package.json affect only dependency sections, automatically merge by preferring newer versions and the side with more dependencies."
    behavior:
      - "Detects conflicts limited to package.json where non-dependency fields are identical between sides"
      - "For dependency sections, merges keys (union)"
      - "On version mismatch, selects newer semver; if indeterminable or equal, prefers the side with more entries"
      - "Writes merged package.json, commits, and pushes changes"
      - "Skips further LLM analysis after successful push"
      - "When both package.json (deps-only) and lockfiles are conflicted, resolves package.json first and then regenerates lockfiles sequentially"
    benefits:
      - "Resolves common dependency bumps without manual intervention"
      - "Prefers safer, newer dependency versions when possible"
      - "Consistent and deterministic merging policy"
    sections:
      - "dependencies"
      - "devDependencies"
      - "peerDependencies"
      - "optionalDependencies"
    implementation:
      - "AutomationEngine._is_package_json_deps_only_conflict"
      - "AutomationEngine._get_deps_only_conflicted_package_json_paths"
      - "AutomationEngine._resolve_package_json_dependency_conflicts"

  commit_formatting_auto_fix:
    name: "Commit auto-fix for dprint formatting"
    description: "When git commit fails due to dprint pre-commit formatting errors, the tool automatically runs 'npx dprint fmt', stages changes, and retries commit once."
    behavior:
      - "Detects dprint-related failures from commit stdout/stderr (e.g., 'Formatting issues detected. Run \'npx dprint fmt\' to fix.')"
      - "Runs 'npx dprint fmt' and stages files, then retries 'git commit'"
      - "If formatting still fails, the commit is reported as failed with the original error"
    implementation:
      - "git_utils.git_commit_with_retry: Centralized commit helper with automatic dprint retry logic"
      - "git_utils.git_push: Centralized push helper for consistent error handling"
      - "All git commit/push operations use these helpers to avoid duplicated logic"
    tests:
      - "tests/test_git_utils.py::TestGitCommitWithRetry::test_successful_commit"
      - "tests/test_git_utils.py::TestGitCommitWithRetry::test_commit_with_dprint_error_and_retry"
      - "tests/test_git_utils.py::TestGitCommitWithRetry::test_commit_with_dprint_error_fmt_fails"
      - "tests/test_git_utils.py::TestGitCommitWithRetry::test_commit_with_non_dprint_error"
      - "tests/test_git_utils.py::TestGitPush::test_successful_push"
      - "tests/test_git_utils.py::TestGitPush::test_push_with_branch"
      - "tests/test_git_utils.py::TestGitPush::test_push_failure"

  llm_invocation_warn_logging:
    name: "Warn log for LLM invocations"
    description: "Emit warning logs whenever an LLM backend (Gemini or Codex CLI) is invoked, to keep LLM calls minimized."
    behavior:
      - "GeminiClient._run_gemini_cli emits warning before invoking gemini CLI"
      - "CodexClient._run_gemini_cli emits warning before invoking codex CLI"
    tests:
      - "tests/test_gemini_client.py::TestGeminiClient::test_llm_invocation_warn_log"
      - "tests/test_codex_client.py::TestCodexClient::test_llm_invocation_warn_log"


  pr_action_oriented_prompt:
    name: "PR Action-Oriented Prompt (No Comments)"
    description: "LLM prompt for PRs forbids posting comments and enforces direct code changes, git add/commit/push, and optional gh pr merge."
    behavior:
      - "Prohibits PR comments or narrative outputs from LLM"
      - "Instructs safe edits to make CI pass"
      - "Requires git add/commit/push to the PR branch"
      - "If mergeable and CI passing, performs gh pr merge"
      - "Standardizes output to a single line starting with ACTION_SUMMARY: or CANNOT_FIX"
    implementation:
      - "AutomationEngine._create_pr_analysis_prompt updated to action-oriented style"
      - "AutomationEngine._apply_pr_actions_directly updated to avoid posting comments and parse ACTION_SUMMARY/CANNOT_FIX"
    tests:
      - "tests/test_automation_engine.py::test_create_pr_prompt_is_action_oriented_no_comments"
      - "tests/test_automation_engine.py::test_apply_pr_actions_directly_does_not_post_comments"

  llm_prompts_yaml_config:
    name: "YAML-configured LLM prompts"
    description: "All LLM instruction prompts (PR, issues, conflicts, test fixes, feature suggestions) are read from src/auto_coder/prompts.yaml."
    behavior:
      - "Central prompt templates defined in YAML with $placeholders"
      - "Functions render prompts via prompt_loader.render_prompt"
      - "Supports cache invalidation and custom prompt paths for tests"
      - "Fail-fast: If prompts.yaml is missing or invalid, terminate immediately (SystemExit) with a clear error message"
    implementation:
      - "prompt_loader.py parses YAML and caches templates; on failure, logs critical and raises SystemExit"
      - "pr_processor, issue_processor, test_runner, gemini_client, qwen_client, conflict_resolver consume YAML prompts"
      - "packaging: prompts.yaml included in wheel/sdist via setuptools package-data; verified via pipx install presence in site-packages"

    tests:
      - "tests/test_prompt_loader.py::test_render_prompt_with_custom_path"
      - "tests/test_prompt_loader.py::test_get_prompt_template_uses_cache"
      - "tests/test_prompt_loader.py::test_missing_prompt_file_causes_system_exit"
      - "tests/test_prompt_loader.py::test_invalid_yaml_causes_system_exit"
      - "tests/test_e2e_prompt_yaml.py::test_pr_prompt_uses_yaml_template"

      - "AutomationEngine._resolve_merge_conflicts_with_gemini updated to use specialized resolver and sequential handling"

  base_branch_merge_for_conflicts:
    name: "PR Base Branch Merge for Updates/Conflicts"
    description: "When updating a PR branch or resolving conflicts, merge the PR's base branch (not necessarily main) into the PR branch."
    behavior:
      - "Detect PR base branch from pr_data.base_branch (or base.ref) and use it as merge target"
      - "Fetch and merge origin/<base_branch> into the PR branch for updates and conflict resolution"
      - "Prompts and logs refer to the actual base branch dynamically"
    benefits:
      - "Handles repositories where default branch is not main (e.g., develop)"
      - "Reduces unnecessary rebases when PR targets a non-main branch"
    implementation:
      - "AutomationEngine._update_with_main_branch (uses base_branch; function name kept for compatibility)"
      - "AutomationEngine._resolve_pr_merge_conflicts"
      - "AutomationEngine._resolve_merge_conflicts_with_gemini (prompt mentions base branch)"
    tests:
      - "tests/test_automation_engine.py::test_resolve_pr_merge_conflicts_uses_base_branch"
      - "tests/test_automation_engine.py::test_update_with_main_branch_uses_provided_base_branch"



  github_actions_fix_commit_push:
    name: "GitHub Actions Fix with Commit/Push"
    description: "When applying fixes from GitHub Actions logs, the LLM is instructed to stage, commit, and push changes to the PR branch within the single-run action."
    behavior:
      - "_apply_github_actions_fix constructs a prompt that includes explicit git add/commit/push commands"
      - "The LLM applies fixes and then executes the git commands to update the PR branch"
      - "The output should summarize changes and include commit/push results for logging"
    benefits:
      - "Ensures fixes are not only generated but also persisted to the PR branch"
      - "Aligns with single-run LLM policy (no analysis-only steps)"
    implementation:
      - "AutomationEngine._apply_github_actions_fix updated to include commit/push instructions"

  simple_merge_fallbacks:
    name: "Simple Non-LLM Merge Fallbacks"
    description: "When gh pr merge fails after conflict resolution, try non-AI simple strategies"
    behavior:
      - "Poll mergeable state briefly via gh pr view --json mergeable"
      - "Fallback to alternative merge methods allowed by repository settings (--merge/--rebase/--squash)"
      - "Do not invoke LLM for these fallbacks"
    benefits:
      - "Avoids unnecessary LLM calls for operational merge issues"
      - "Improves success rate by adapting to repo settings"
      - "Handles delayed mergeability on GitHub side"
    implementation:
      - "AutomationEngine._poll_pr_mergeable"
      - "AutomationEngine._get_allowed_merge_methods"

  pr_checks_fail_skip_main_update:
    name: "Skip Base Branch Update When PR Checks Fail"
    description: "Adds a CLI option to skip merging the PR's base branch into PR branches when CI checks are failing; default is to skip."
    behavior:
      - "On failing CI checks, the engine skips updating PR branch with the base branch and proceeds directly to GitHub Actions log extraction and fix attempts."
      - "If --no-skip-main-update is provided, the engine will attempt to merge the base branch into PR branch first (previous behavior)."
    implementation:
      - "AutomationConfig.SKIP_MAIN_UPDATE_WHEN_CHECKS_FAIL (default True)"
      - "AutomationEngine._handle_pr_merge respects the flag and branches logic accordingly"
      - "CLI flag --skip-main-update/--no-skip-main-update wires to the config"
      - "CLI and AutomationEngine log the main-update policy explicitly at runtime"
    tests:
      - "tests/test_cli_process_issues.py::TestCLIProcessIssues::test_process_issues_no_skip_main_update_flag"
      - "tests/test_cli_process_issues.py::TestCLIProcessIssues::test_process_issues_success_default_codex (verifies default True)"
      - "tests/test_automation_engine.py::TestAutomationEngineExtended::test_handle_pr_merge_skips_main_update_when_flag_true"

      - "AutomationEngine._merge_pr updated to use these fallbacks"

  actions_log_fetcher:
    name: "GitHub Actions URL Log Fetcher"
    description: "Fetch error logs from a GitHub Actions job URL for debugging"
    components:
      - name: "AutomationEngine.get_github_actions_logs_from_url"
        file: "src/auto_coder/automation_engine.py"
        description: |
          Retrieve error logs from a GitHub Actions job URL, focusing on:
          - Filter to only include failing steps when step metadata is available via `gh api repos/{owner}/{repo}/actions/jobs/{job_id}`
          - Match step logs by normalized step names against step log filenames and headers
          - Preserve Playwright/Jest expectation blocks (Expected/Received) verbatim
          - Strict prelude trimming via _slice_relevant_error_window with triggers including:
            - Expected substring / Received string / expect(received)
            - Error headers / .spec.ts / ##[error]
            - Command failed/Process completed exit code
            - notice/##[notice] and "error was not a part of any test"
          - ZIP and text log paths both ensure slicing is applied at the end.
          - Step snippets include only error-bearing content (e2e .spec.ts/expect/exit code markers), non-error steps are excluded.
          - Appends a --- Summary --- block when failure summary lines are present.
      - name: "CLI command get-actions-logs"
        file: "src/auto_coder/cli.py"
        description: |
          CLI command to fetch GitHub Actions job logs for debugging.
          - Logger output is routed to stderr to avoid polluting stdout (which is intended to be piped to files).
          - Token source messages are logged (stderr) instead of echoed to stdout.
    tests:
      - "tests/test_actions_log_cli_e2e.py::test_get_actions_logs_cli"
      - "tests/test_github_actions_logs_from_url.py::test_get_github_actions_logs_from_url_fetches_job_zip_and_extracts_errors"
      - "tests/test_github_actions_logs.py::test_get_github_actions_logs_uses_gh_api_and_extracts_errors"
      - "tests/test_github_actions_logs_fallback.py::test_get_github_actions_logs_fallback_to_text_when_zip_fails"
      - "tests/test_actions_log_prelude_strip.py::test_cli_get_actions_logs_strips_prelude_and_is_compact"

testing:
  unit_tests:
    description: "Unit tests for individual components"
    files:
      - "tests/test_github_client.py"
      - "tests/test_gemini_client.py"
      - "tests/test_automation_engine.py"
      - "tests/test_cli_main.py"
      - "tests/test_cli_process_issues.py"
      - "tests/test_cli_create_feature_issues.py"
      - "tests/test_config.py"
    coverage: "All public methods and error conditions"

  integration_tests:
    description: "Integration tests for component interactions"
    included_in: "tests/test_automation_engine.py"
    coverage: "GitHub-Gemini integration, CLI-Engine integration"

  e2e_tests:
    description: "End-to-end tests for complete workflows"
    files:
      - "tests/test_e2e.py"
    coverage: "Complete automation workflows, CLI integration"

deployment:
  installation:
    method: "pip install"
    requirements: "Python 3.9+"
    dependencies: "Listed in pyproject.toml"

  configuration:
    environment_variables:
      required:
        - "GITHUB_TOKEN"
        - "GEMINI_API_KEY"
      optional:
        - "GITHUB_API_URL"
        - "GEMINI_MODEL"
        - "MAX_ISSUES_PER_RUN"
        - "MAX_PRS_PER_RUN"
        - "DRY_RUN"
        - "LOG_LEVEL"

  ci:
    github_actions_pr_checks:
      name: "GitHub Actions PR Checks"
      description: "Run lint, type-check, and tests on every push/PR; gate merges on required checks."
      workflow_file: ".github/workflows/ci.yml"
      jobs:
        - id: "lint"
          name: "Lint & Type Check"
          steps:
            - "actions/checkout@v4"
            - "actions/setup-python@v5 (python=3.12)"
            - "pip install -e .[dev]"
            - "black --check src/ tests/"
            - "isort --check-only src/ tests/"
            - "flake8 src/ tests/"
            - "mypy src/"
        - id: "tests"
          name: "Tests (pytest)"
          matrix: ["3.11", "3.12"]
          steps:
            - "actions/checkout@v4"
            - "actions/setup-python@v5 (python=${{ matrix.python-version }})"
            - "pip install -e .[dev,test]"
            - "pytest -v"
      tests:
        - "tests/test_ci_workflow.py::test_github_actions_ci_workflow_exists_and_has_required_jobs"

  qwen_integration:
    name: "Qwen Code Integration"
    description: "Integration with Qwen Code CLI for single-run direct actions (no analysis-only calls)."
    migration_plan_phase3:
      goal: "Eliminate 'gemini' from internal method names in QwenClient while preserving engine compatibility"
      impacted_components:
        - "AutomationEngine (calls _run_gemini_cli on client object)"
        - "QwenClient (private method names)"
        - "Tests referencing _run_gemini_cli/_run_qwen_cli"
      strategy:
        - "Make _run_qwen_cli the primary implementation in QwenClient"
        - "Keep _run_gemini_cli as a delegating alias during transition"
        - "Update internal QwenClient calls (e.g., suggest_features) to use _run_qwen_cli"
        - "Plan a later phase to rename AutomationEngine.gemini and callers to neutral naming before alias removal"
      deprecation:
        - "Mark _run_gemini_cli as temporary alias; remove after engine rename and downstream updates"

    migration_plan_phase4:
      goal: "Neutralize AutomationEngine LLM invocation naming and reduce alias dependencies"
      impacted_components:
        - "AutomationEngine (introduce _run_llm_cli helper; progressively replace call sites)"
        - "GeminiClient/QwenClient/CodexClient/CodexMCPClient (add _run_llm_cli delegating alias)"
        - "CLI/Docs/Tests (ensure consistency)"
      strategy:
        - "Phase 1: Introduce _run_llm_cli in all clients, keep existing methods for compatibility"
        - "Phase 2: Replace AutomationEngine call sites to use self._run_llm_cli(...) while keeping self.gemini attr"
        - "Phase 3: Plan removal conditions for QwenClient._run_gemini_cli alias once engine neutralization reaches 100% and downstream usage is gone"
      deprecation:
        - "Deprecate QwenClient._run_gemini_cli; remove after a grace period when CI shows zero usages across engine/tests"
      tests:
        - "tests/test_llm_cli_neutral.py::test_gemini_client_llm_alias"
        - "tests/test_llm_cli_neutral.py::test_qwen_client_llm_alias"
        - "tests/test_llm_cli_neutral.py::test_codex_client_llm_alias"

    provider_fallback:
      name: "Qwen OAuth usage limit fallback"
      description: |
        Prefer configured OpenAI-compatible providers (ModelStudio, OpenRouter, etc.)
        before falling back to the shared Qwen OAuth pool when usage limits occur.
      configuration:
        files:
          - path: "~/.auto-coder/qwen-providers.toml"
            description: |
              TOML file defining fallback providers. Each entry supplies ``name`` and
              ``api_key``; known providers auto-fill ``base_url``/``model``.
          - env: "AUTO_CODER_QWEN_CONFIG"
            description: "Override the exact config file path"
          - env: "AUTO_CODER_CONFIG_DIR"
            description: "Override the directory that contains qwen-providers.toml"
      behavior:
        - "Providers are attempted in file order before OAuth"
        - "OPENAI_API_KEY/OPENAI_BASE_URL/OPENAI_MODEL are injected per provider"
        - "Successful provider becomes the active default for subsequent calls"
        - "Aggregates AutoCoderUsageLimitError details if all providers are exhausted"
      implementation:
        - "src/auto_coder/qwen_client.py"
        - "src/auto_coder/qwen_provider_config.py"
      tests:
        - "tests/test_qwen_provider_config.py::test_load_qwen_provider_configs_defaults"
        - "tests/test_qwen_provider_config.py::test_load_qwen_provider_configs_skips_missing_key"
        - "tests/test_qwen_client_fallback.py::test_qwen_client_prefers_configured_api_keys_before_oauth"
        - "tests/test_qwen_client_fallback.py::test_qwen_client_fallback_to_openrouter"
        - "tests/test_qwen_client_fallback.py::test_qwen_client_fallbacks_to_oauth_after_api_keys"
        - "tests/test_qwen_client_fallback.py::test_qwen_client_all_limits_raise"

    backend_manager:
      name: "Cyclic Multi-Backend Manager"
      description: "Manages multiple AI backends and switches cyclically on usage limits or repeated failures."
      behavior:
        - "Detects AutoCoderUsageLimitError from clients and rotates to the next backend; tries each backend at most once per prompt"
        - "apply_workspace_test_fix: when the same model receives the same prompt 3 times consecutively, rotate to the next backend before executing the 3rd call"
        - "When a different prompt arrives, revert to the default backend"
        - "Order is cyclic among: codex -> codex-mcp -> gemini -> qwen -> auggie (starting from selected default)"
      implementation:
        - file: "src/auto_coder/backend_manager.py"
        - methods:
          - "_run_llm_cli(prompt)"
          - "run_test_fix_prompt(prompt)"
          - "switch_to_next_backend() / switch_to_default_backend()"
      client_side_limit_detection:
        - "Clients raise AutoCoderUsageLimitError on rate/quota limit detection in CLI outputs"
        - files:
          - "src/auto_coder/gemini_client.py"
          - "src/auto_coder/qwen_client.py"
          - "src/auto_coder/codex_client.py"
      cli_wiring:
        - "CLI constructs the selected backend immediately (preserving tests that assert constructor args) and wraps it with BackendManager that lazily instantiates alternates"
        - files:
          - "src/auto_coder/cli.py"
      tests:
        - "tests/test_backend_manager.py::test_manager_switches_on_usage_limit"
        - "tests/test_backend_manager.py::test_run_test_fix_prompt_switch_after_three_same_prompts"
        - "tests/test_apply_workspace_test_fix_switch.py::test_apply_workspace_test_fix_switch_after_three_same_prompts"
      hardening_2025_09:
        description: "Hardened usage limit detection for Gemini streaming errors to ensure BackendManager rotation on quota exhaustion."
        recognizes:
          - "rate limit"
          - "quota"
          - "429"
          - "RESOURCE_EXHAUSTED"
          - "Too Many Requests"
        tests:
          - "tests/test_usage_limit_detection.py::test_gemini_raises_usage_limit_on_zero_with_429_only"
          - "tests/test_usage_limit_detection.py::test_gemini_raises_usage_limit_on_zero_with_resource_exhausted"
      hardening_2025_09_codex:
        description: "Detect Codex CLI upgrade banner that signals usage/quota exhaustion."
        recognizes:
          - "usage limit"
          - "Upgrade to Pro"
        sample_error: "[2025-09-24T07:13:47] ERROR: You've hit your usage limit. Upgrade to Pro (...)"
        tests:
          - "tests/test_usage_limit_detection.py::test_codex_raises_usage_limit_on_upgrade_to_pro_message"
          - "tests/test_cli_codex_usage_limit_e2e.py::test_codex_cli_usage_limit_detection_e2e"

    components:
      - name: "QwenClient"
        file: "src/auto_coder/qwen_client.py"
        methods:
          - name: "suggest_features"
            description: "Suggest new features based on repository analysis via Qwen Code"
            parameters: ["repo_context"]
            returns: "List of feature suggestions"
          - name: "switch_to_conflict_model"
            description: "No-op switch for conflict resolution (same model by default)"
            parameters: []
            returns: "None"
          - name: "switch_to_default_model"
            description: "No-op switch back to default model"
            parameters: []
            returns: "None"
          - name: "_run_qwen_cli"
            description: "Primary method: run qwen CLI non-interactively (-p/--prompt); prefers -m/--model; sets OPENAI_MODEL and applies OPENAI_API_KEY/OPENAI_BASE_URL env when provided; streams output"
            parameters: ["prompt"]
            returns: "Aggregated CLI output text"

          - name: "_run_gemini_cli"
            description: "Temporary alias delegating to _run_qwen_cli (for AutomationEngine compatibility)"
            parameters: ["prompt"]
            returns: "Aggregated CLI output text"

          - name: "_run_llm_cli"
            description: "Neutral method delegating to _run_qwen_cli; preferred by AutomationEngine during migration"
            parameters: ["prompt"]
            returns: "Aggregated CLI output text"


        probes:
          - name: "qwen_help_has_flags"
            file: "src/auto_coder/cli_helpers.py"
            description: "Lightweight probe executing 'qwen --help' to verify required flags; tolerates short/long forms (-p/--prompt, -m/--model) and normalizes ANSI/whitespace/dashes; fully mocked in CI"
            tests:
              - "tests/test_qwen_help_probe.py::test_qwen_help_probe_detects_required_flags"
              - "tests/test_qwen_help_probe.py::test_qwen_help_probe_missing_flag_returns_false"
              - "tests/test_qwen_help_probe.py::test_qwen_help_probe_accepts_long_form_for_short_flags"
              - "tests/test_qwen_help_probe.py::test_qwen_help_probe_accepts_short_form_for_long_flags"
              - "tests/test_qwen_help_probe_extra.py::test_qwen_help_probe_handles_trailing_space_and_text"
              - "tests/test_qwen_help_probe_extra.py::test_qwen_help_probe_handles_table_style"

        cli_options:
          - name: "--openai-api-key"
            scope: "backend=qwen only"
            envvar: "OPENAI_API_KEY"
            description: "OpenAI-style API key forwarded to QwenClient and exported to env for qwen CLI invocations"
          - name: "--openai-base-url"
            scope: "backend=qwen only"
            envvar: "OPENAI_BASE_URL"
            description: "OpenAI-style Base URL forwarded to QwenClient and exported to env for qwen CLI invocations"

  auggie_integration:
    name: "Auggie CLI Integration"
    description: "Integration with Auggie CLI for non-interactive execution. Defaults to the GPT-5 model when the user does not override --model. Enforces a daily call ceiling to prevent accidental overuse."
    components:
      - name: "AuggieClient"
        file: "src/auto_coder/auggie_client.py"
        methods:
          - name: "_run_auggie_cli"
            description: "Invoke `auggie --print --model <model> "<prompt>"` and stream output via logger; raises AutoCoderUsageLimitError on rate-limit phrases."
            parameters: ["prompt"]
            returns: "Aggregated CLI output text"
          - name: "switch_to_conflict_model"
            description: "Compatibility no-op; Auggie uses the same model for conflict handling."
            parameters: []
            returns: "None"
          - name: "switch_to_default_model"
            description: "Compatibility no-op; Auggie sticks to the configured model."
            parameters: []
            returns: "None"
          - name: "_check_and_increment_usage"
            description: "Persisted counter that caps Auggie invocations at 20 per day and raises AutoCoderUsageLimitError before exceeding the quota."
            parameters: []
            returns: "None"

    cli_support:
      defaults:
        model: "GPT-5 (default)"
      checks:
        - "cli.check_auggie_cli_or_fail performs `auggie --version` probe and instructs installation via npm"
      tests:
        - "tests/test_cli_auggie.py::test_process_issues_backend_auggie_defaults_to_gpt5"
        - "tests/test_cli_auggie.py::test_process_issues_backend_auggie_respects_model_override"
        - "tests/test_cli_auggie.py::test_create_feature_issues_backend_auggie"
        - "tests/test_cli_auggie.py::test_fix_to_pass_tests_backend_auggie_default_model"
        - "tests/test_auggie_client_daily_limit.py::test_auggie_usage_limit_blocks_21st_call"
        - "tests/test_cli_auggie_usage_limit_e2e.py::test_process_issues_rotates_when_auggie_daily_limit_reached"

  graphrag_integration:
    name: "GraphRAG Integration"
    description: "Integration with GraphRAG MCP server for enhanced code context using Neo4j (graph database) and Qdrant (vector database). GraphRAG is always enabled and automatically initialized at startup for all commands (process-issues, create-feature-issues, fix-to-pass-tests)."
    components:
      - name: "GraphRAGDockerManager"
        file: "src/auto_coder/graphrag_docker_manager.py"
        description: "Manages Neo4j and Qdrant Docker containers"
        methods:
          - name: "start"
            description: "Start Neo4j and Qdrant containers"
            parameters: ["wait_for_health", "timeout"]
            returns: "Boolean indicating success"
          - name: "stop"
            description: "Stop Neo4j and Qdrant containers"
            parameters: ["timeout"]
            returns: "Boolean indicating success"
          - name: "is_running"
            description: "Check if containers are running"
            parameters: []
            returns: "Boolean indicating if both containers are running"
          - name: "get_status"
            description: "Get health status of containers"
            parameters: []
            returns: "Dictionary with container names and health status"
          - name: "wait_for_health"
            description: "Wait for containers to be healthy"
            parameters: ["timeout", "check_interval"]
            returns: "Boolean indicating if containers are healthy"
        tests:
          - "tests/test_graphrag_docker_manager.py"
      - name: "GraphRAGIndexManager"
        file: "src/auto_coder/graphrag_index_manager.py"
        description: "Manages indexing of codebase into Neo4j and Qdrant"
        methods:
          - name: "is_index_up_to_date"
            description: "Check if index is up to date with codebase"
            parameters: []
            returns: "Boolean indicating if index is up to date"
          - name: "update_index"
            description: "Update index if needed"
            parameters: ["force"]
            returns: "Boolean indicating success"
          - name: "ensure_index_up_to_date"
            description: "Ensure index is up to date, updating if necessary"
            parameters: []
            returns: "Boolean indicating success"
        tests:
          - "tests/test_graphrag_index_manager.py"
      - name: "GraphRAGMCPIntegration"
        file: "src/auto_coder/graphrag_mcp_integration.py"
        description: "Integrates graphrag_mcp server with LLM clients"
        methods:
          - name: "ensure_ready"
            description: "Ensure GraphRAG environment is ready (Docker containers, index, MCP server)"
            parameters: []
            returns: "Boolean indicating if environment is ready"
          - name: "start_mcp_server"
            description: "Start graphrag_mcp server"
            parameters: []
            returns: "Boolean indicating success"
          - name: "stop_mcp_server"
            description: "Stop graphrag_mcp server"
            parameters: []
            returns: "Boolean indicating success"
          - name: "is_mcp_server_running"
            description: "Check if MCP server is running"
            parameters: []
            returns: "Boolean indicating if server is running"
          - name: "get_mcp_config_for_llm"
            description: "Get MCP configuration to pass to LLM client"
            parameters: []
            returns: "Dictionary with MCP configuration or None"
        tests:
          - "tests/test_graphrag_mcp_integration.py"
    cli_commands:
      - command: "auto-coder graphrag start"
        description: "Start Neo4j and Qdrant Docker containers"
        options:
          - "--wait/--no-wait: Wait for containers to be healthy (default: True)"
          - "--timeout: Health check timeout in seconds (default: 120)"
      - command: "auto-coder graphrag stop"
        description: "Stop Neo4j and Qdrant Docker containers"
        options:
          - "--timeout: Command timeout in seconds (default: 60)"
      - command: "auto-coder graphrag status"
        description: "Check status of Neo4j and Qdrant Docker containers"
      - command: "auto-coder graphrag update-index"
        description: "Update codebase index in Neo4j and Qdrant"
        options:
          - "--force: Force update even if index is up to date"
          - "--repo-path: Path to repository to index (default: current directory)"
    integration:
      - name: "CodexMCPClient GraphRAG Support"
        description: "CodexMCPClient always uses GraphRAG integration (always enabled)"
        file: "src/auto_coder/codex_mcp_client.py"
        parameters:
          - "enable_graphrag: Enable GraphRAG integration (always True)"
        behavior:
          - "GraphRAG is always enabled and initialized at startup"
          - "Automatically starts Docker containers if not running"
          - "Updates index if outdated (failure is fatal)"
          - "Starts MCP server if configured (failure is fatal)"
          - "All GraphRAG initialization failures will terminate the process"
        tests:
          - "tests/test_codex_mcp_client_graphrag.py"
    external_dependencies:
      - name: "graphrag_mcp"
        url: "https://github.com/rileylemm/graphrag_mcp"
        description: "MCP server for querying hybrid graph and vector database"
        tools:
          - "search_documentation: Semantic search using Qdrant"
          - "hybrid_search: Combined semantic and graph-based search"
        resources:
          - "https://graphrag.db/schema/neo4j: Neo4j schema information"
          - "https://graphrag.db/collection/qdrant: Qdrant collection information"
      - name: "Neo4j"
        description: "Graph database for storing code relationships"
        default_port: 7687
      - name: "Qdrant"
        description: "Vector database for storing code embeddings"
        default_port: 6333

  usage:
    examples:
      # Note: GraphRAG is always enabled for all commands. Containers are automatically started if not running.
      - command: "auto-coder process-issues --repo owner/repo"
        description: "Process issues and PRs with codex backend (default); jules mode and GraphRAG are ON by default"
      - command: "auto-coder process-issues --repo owner/repo --backend gemini --model-gemini gemini-2.5-pro"
        description: "Process issues and PRs using Gemini backend with GraphRAG (you can override the model via --model-gemini)"
      - command: "auto-coder process-issues --repo owner/repo --backend qwen --model-qwen qwen3-coder-plus"
        description: "Process issues and PRs using Qwen Code backend with GraphRAG (you can override the model via --model-qwen)"
      - command: "auto-coder process-issues --repo owner/repo --backend auggie"
        description: "Process issues and PRs using Auggie backend with GraphRAG (defaults to GPT-5; override with --model-auggie)"
      - command: "auto-coder process-issues --repo owner/repo --backend codex --backend gemini"
        description: "Process issues with codex as the default backend and fall back to Gemini if limits are hit (GraphRAG enabled)"
      - command: "auto-coder create-feature-issues --repo owner/repo --backend qwen --model qwen3-coder-plus"
        description: "Create feature enhancement issues using Qwen Code backend with GraphRAG"
      - command: "auto-coder create-feature-issues --repo owner/repo --backend auggie"
        description: "Create feature enhancement issues using Auggie backend with GraphRAG (defaults to GPT-5)"
      - command: "auto-coder create-feature-issues --repo owner/repo --backend codex --backend gemini"
        description: "Create feature issues with codex default and Gemini fallback order (GraphRAG enabled)"
      - command: "auto-coder fix-to-pass-tests --backend qwen --model qwen3-coder-plus"
        description: "Run local tests and request fixes using Qwen Code backend with GraphRAG"
      - command: "auto-coder fix-to-pass-tests --backend auggie"
        description: "Run local tests and request fixes using Auggie backend with GraphRAG (defaults to GPT-5)"
      - command: "auto-coder fix-to-pass-tests --backend codex --backend gemini"
        description: "Run fix-to-pass-tests with codex by default and Gemini as a secondary option (GraphRAG enabled)"

      - command: "auto-coder process-issues --repo owner/repo --no-jules-mode"
        description: "Disable jules mode and process issues with AI analysis"
      - command: "auto-coder process-issues --repo owner/repo --backend codex-mcp"
        description: "Process issues and PRs using Codex MCP backend (persistent session for a single PR or a single error-fix)"
      - command: "auto-coder create-feature-issues --repo owner/repo --backend codex-mcp"
        description: "Create feature enhancement issues using Codex MCP backend (persistent session)"
      - command: "auto-coder fix-to-pass-tests --backend codex-mcp"
        description: "Run local tests and request fixes using Codex MCP backend (session maintained); --model is ignored"

      - command: "auto-coder process-issues --repo owner/repo --jules-mode --dry-run"
        description: "Run jules mode in dry-run mode"
      - command: "auto-coder process-issues --repo owner/repo --only 123"
        description: "Process only issue/PR #123"
      - command: "auto-coder process-issues --repo owner/repo --only https://github.com/owner/repo/pull/456"
        description: "Process only PR #456 by URL"
      - command: "auto-coder create-feature-issues --repo owner/repo"
        description: "Create feature enhancement issues"

      # GraphRAG Integration Examples
      # Note: GraphRAG is always enabled. Containers are automatically started if not running.
      - command: "auto-coder graphrag start"
        description: "Manually start Neo4j and Qdrant Docker containers for GraphRAG"
      - command: "auto-coder graphrag stop"
        description: "Stop GraphRAG Docker containers"
      - command: "auto-coder graphrag status"
        description: "Check status of GraphRAG Docker containers"
      - command: "auto-coder graphrag update-index"
        description: "Update codebase index in Neo4j and Qdrant"
      - command: "auto-coder graphrag update-index --force"
        description: "Force update index even if it's up to date"
      - command: "auto-coder process-issues --repo owner/repo"
        description: "Process issues with GraphRAG integration (always enabled, containers auto-started if needed)"
