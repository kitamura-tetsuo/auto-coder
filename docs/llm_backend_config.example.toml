# LLM Backend Configuration Example
# =================================
#
# This file demonstrates how to configure LLM backends for Auto-Coder.
# Save this file as `~/.auto-coder/llm_config.toml` or specify a custom path.

[backend]
# Default backend to use when multiple are available
default = "qwen"

# Order of backends to try (only enabled backends will be used)
order = ["qwen", "gemini", "codex", "claude"]

[message_backend]
# Separate configuration for message generation (commit messages, PR descriptions)
# If not specified, falls back to general backend configuration
default = "qwen"
order = ["qwen", "gemini"]

[backends]

# Qwen Configuration
# ------------------
[qwen]
enabled = true
model = "qwen3-coder-plus"

# OpenAI-compatible API settings (for qwen via codex CLI)
openai_api_key = "your-qwen-api-key-here"
openai_base_url = "https://api.qwen.com/v1"

# Additional options to pass to the Qwen CLI
# These options will be added to the command line when calling qwen or codex
# Example: ["-o", "stream", "false", "--debug"]
options = []

# Backend type identifier (can be used for aliases)
# This allows creating custom names that map to underlying backend types
backend_type = "qwen"

# Gemini Configuration
# --------------------
[gemini]
enabled = true
model = "gemini-2.5-pro"

# Gemini API settings
api_key = "your-gemini-api-key-here"
base_url = "https://generativelanguage.googleapis.com"

# Optional retry configuration for usage limits
usage_limit_retry_count = 3
usage_limit_retry_wait_seconds = 30
# Rotate to the next backend after every successful call to stay under strict execution limits
always_switch_after_execution = true

# Gemini doesn't support custom options in the same way as qwen
# Options field is mainly used for qwen backend
options = []
backend_type = "gemini"

# Codex Configuration
# -------------------
[codex]
enabled = true
model = "codex"
# Codex typically doesn't need API keys as it's handled by providers
options = []
backend_type = "codex"

# Custom Alias Example
# --------------------
# You can create custom aliases that point to underlying backend types
# This allows you to have multiple configurations for the same backend
[qwen-fast]
enabled = true
model = "qwen-turbo"
openai_api_key = "your-qwen-api-key-here"
openai_base_url = "https://api.qwen.com/v1"

# Use 'qwen' backend type but with different options
backend_type = "qwen"

# Custom options for this alias (e.g., faster model, different settings)
options = ["-o", "timeout", "30", "-o", "stream", "true"]

[qwen-debug]
enabled = true
model = "qwen3-coder-plus"
openai_api_key = "your-qwen-api-key-here"
openai_base_url = "https://api.qwen.com/v1"

# Use 'qwen' backend type with debug options
backend_type = "qwen"

# Debug-specific options
options = ["--verbose", "--debug", "-o", "output_format", "json"]

# Azure OpenAI Configuration Example
# ----------------------------------
# This example shows how to configure qwen with Azure OpenAI endpoint
[qwen-azure]
enabled = false  # Set to true if using Azure
model = "qwen-35-coder"
openai_api_key = "your-azure-openai-key"
openai_base_url = "https://your-resource.openai.azure.com"

# Azure-specific options
backend_type = "qwen"
options = ["-o", "api_version", "2024-02-01"]

# OpenRouter Configuration Example
# --------------------------------
# Example using OpenRouter as a provider for qwen
[qwen-openrouter]
enabled = false  # Set to true if using OpenRouter
model = "qwen/qwen-2.5-coder-32k-instruct"
openai_api_key = "sk-or-v1-your-key-here"
openai_base_url = "https://openrouter.ai/api/v1"

# OpenRouter-specific options
backend_type = "qwen"
options = ["-o", "HTTPReferer", "https://yourapp.com", "-o", "XTitle", "Auto-Coder"]

# Notes:
# ------
# 1. The `options` field is primarily used by the qwen backend to pass
#    command-line arguments to the qwen or codex CLI tools.
#
# 2. The `backend_type` field allows you to create custom aliases that
#    map to underlying backend implementations. This is useful when you
#    want multiple configurations for the same backend type.
#
# 3. Only the qwen backend currently utilizes the `options` field in its
#    subprocess calls. Other backends may ignore this field.
#
# 4. Environment variables can override configuration values:
#    - AUTO_CODER_DEFAULT_BACKEND
#    - AUTO_CODER_MESSAGE_DEFAULT_BACKEND
#    - AUTO_CODER_<BACKEND>_API_KEY (e.g., AUTO_CODER_GEMINI_API_KEY)
#    - AUTO_CODER_OPENAI_API_KEY (global fallback)
#    - AUTO_CODER_<BACKEND>_OPENAI_API_KEY (e.g., AUTO_CODER_QWEN_OPENAI_API_KEY)
#    - AUTO_CODER_OPENAI_BASE_URL (global fallback)
#    - AUTO_CODER_<BACKEND>_OPENAI_BASE_URL
#
# 5. Provider-specific configurations (like Azure OpenAI or OpenRouter)
#    should use the openai_api_key and openai_base_url fields.
